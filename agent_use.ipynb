{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30949438-eb12-40c0-8445-33aee6864dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Till Zemann\n",
    "# License: MIT License\n",
    "\n",
    "# https://gymnasium.farama.org/tutorials/training_agents/blackjack_tutorial/\n",
    "# https://gymnasium.farama.org/environments/toy_text/blackjack/\n",
    "# https://github.com/openai/gym/blob/master/gym/envs/toy_text/blackjack.py\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "\n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from gymnasium.error import DependencyNotInstalled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c28e1d2e-cba5-4918-b06d-37c830fb263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmp(a, b):\n",
    "    return float(a > b) - float(a < b)\n",
    "\n",
    "\n",
    "# 1 = Ace, 2-10 = Number cards, Jack/Queen/King = 10\n",
    "deck = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 10]\n",
    "\n",
    "\n",
    "def draw_card(np_random):\n",
    "    return int(np_random.choice(deck))\n",
    "\n",
    "\n",
    "def draw_hand(np_random):\n",
    "    return [draw_card(np_random), draw_card(np_random)]\n",
    "\n",
    "\n",
    "def usable_ace(hand):  # Does this hand have a usable ace?\n",
    "    return 1 in hand and sum(hand) + 10 <= 21\n",
    "\n",
    "\n",
    "def sum_hand(hand):  # Return current hand total\n",
    "    if usable_ace(hand):\n",
    "        return sum(hand) + 10\n",
    "    return sum(hand)\n",
    "\n",
    "\n",
    "def is_bust(hand):  # Is this hand a bust?\n",
    "    return sum_hand(hand) > 21\n",
    "\n",
    "\n",
    "def score(hand):  # What is the score of this hand (0 if bust)\n",
    "    return 0 if is_bust(hand) else sum_hand(hand)\n",
    "\n",
    "\n",
    "def is_natural(hand):  # Is this hand a natural blackjack?\n",
    "    return sorted(hand) == [1, 10]\n",
    "\n",
    "\n",
    "class BlackjackEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Blackjack is a card game where the goal is to beat the dealer by obtaining cards\n",
    "    that sum to closer to 21 (without going over 21) than the dealers cards.\n",
    "\n",
    "    ### Description\n",
    "    Card Values:\n",
    "\n",
    "    - Face cards (Jack, Queen, King) have a point value of 10.\n",
    "    - Aces can either count as 11 (called a 'usable ace') or 1.\n",
    "    - Numerical cards (2-9) have a value equal to their number.\n",
    "\n",
    "    This game is played with an infinite deck (or with replacement).\n",
    "    The game starts with the dealer having one face up and one face down card,\n",
    "    while the player has two face up cards.\n",
    "\n",
    "    The player can request additional cards (hit, action=1) until they decide to stop (stick, action=0)\n",
    "    or exceed 21 (bust, immediate loss).\n",
    "    After the player sticks, the dealer reveals their facedown card, and draws\n",
    "    until their sum is 17 or greater.  If the dealer goes bust, the player wins.\n",
    "    If neither the player nor the dealer busts, the outcome (win, lose, draw) is\n",
    "    decided by whose sum is closer to 21.\n",
    "\n",
    "    ### Action Space\n",
    "    There are two actions: stick (0), and hit (1).\n",
    "\n",
    "    ### Observation Space\n",
    "    The observation consists of a 3-tuple containing: the player's current sum,\n",
    "    the value of the dealer's one showing card (1-10 where 1 is ace),\n",
    "    and whether the player holds a usable ace (0 or 1).\n",
    "\n",
    "    This environment corresponds to the version of the blackjack problem\n",
    "    described in Example 5.1 in Reinforcement Learning: An Introduction\n",
    "    by Sutton and Barto (http://incompleteideas.net/book/the-book-2nd.html).\n",
    "\n",
    "    ### Rewards\n",
    "    - win game: +1\n",
    "    - lose game: -1\n",
    "    - draw game: 0\n",
    "    - win game with natural blackjack:\n",
    "\n",
    "        +1.5 (if <a href=\"#nat\">natural</a> is True)\n",
    "\n",
    "        +1 (if <a href=\"#nat\">natural</a> is False)\n",
    "\n",
    "    ### Arguments\n",
    "\n",
    "    ```\n",
    "    gym.make('Blackjack-v1', natural=False, sab=False)\n",
    "    ```\n",
    "\n",
    "    <a id=\"nat\">`natural=False`</a>: Whether to give an additional reward for\n",
    "    starting with a natural blackjack, i.e. starting with an ace and ten (sum is 21).\n",
    "\n",
    "    <a id=\"sab\">`sab=False`</a>: Whether to follow the exact rules outlined in the book by\n",
    "    Sutton and Barto. If `sab` is `True`, the keyword argument `natural` will be ignored.\n",
    "    If the player achieves a natural blackjack and the dealer does not, the player\n",
    "    will win (i.e. get a reward of +1). The reverse rule does not apply.\n",
    "    If both the player and the dealer get a natural, it will be a draw (i.e. reward 0).\n",
    "\n",
    "    ### Version History\n",
    "    * v0: Initial versions release (1.0.0)\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {\n",
    "        \"render_modes\": [\"human\", \"rgb_array\"],\n",
    "        \"render_fps\": 4,\n",
    "    }\n",
    "\n",
    "    def __init__(self, render_mode: Optional[str] = None, natural=False, sab=False):\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "        self.observation_space = spaces.Tuple(\n",
    "            (spaces.Discrete(32), spaces.Discrete(11), spaces.Discrete(2))\n",
    "        )\n",
    "\n",
    "        # Flag to payout 1.5 on a \"natural\" blackjack win, like casino rules\n",
    "        # Ref: http://www.bicyclecards.com/how-to-play/blackjack/\n",
    "        self.natural = natural\n",
    "\n",
    "        # Flag for full agreement with the (Sutton and Barto, 2018) definition. Overrides self.natural\n",
    "        self.sab = sab\n",
    "\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "    def step(self, action):\n",
    "        assert self.action_space.contains(action)\n",
    "        if action:  # hit: add a card to players hand and return\n",
    "            self.player.append(draw_card(self.np_random))\n",
    "            if is_bust(self.player):\n",
    "                terminated = True\n",
    "                reward = -1.0\n",
    "            else:\n",
    "                terminated = False\n",
    "                reward = 0.0\n",
    "        else:  # stick: play out the dealers hand, and score\n",
    "            terminated = True\n",
    "            while sum_hand(self.dealer) < 17:\n",
    "                self.dealer.append(draw_card(self.np_random))\n",
    "            reward = cmp(score(self.player), score(self.dealer))\n",
    "            if self.sab and is_natural(self.player) and not is_natural(self.dealer):\n",
    "                # Player automatically wins. Rules consistent with S&B\n",
    "                reward = 1.0\n",
    "            elif (\n",
    "                not self.sab\n",
    "                and self.natural\n",
    "                and is_natural(self.player)\n",
    "                and reward == 1.0\n",
    "            ):\n",
    "                # Natural gives extra points, but doesn't autowin. Legacy implementation\n",
    "                reward = 1.5\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "        return self._get_obs(), reward, terminated, False, {}\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return (sum_hand(self.player), self.dealer[0], usable_ace(self.player))\n",
    "\n",
    "    def reset(\n",
    "        self,\n",
    "        seed: Optional[int] = None,\n",
    "        options: Optional[dict] = None,\n",
    "    ):\n",
    "        super().reset(seed=seed)\n",
    "        self.dealer = draw_hand(self.np_random)\n",
    "        self.player = draw_hand(self.np_random)\n",
    "\n",
    "        _, dealer_card_value, _ = self._get_obs()\n",
    "\n",
    "        suits = [\"C\", \"D\", \"H\", \"S\"]\n",
    "        self.dealer_top_card_suit = self.np_random.choice(suits)\n",
    "\n",
    "        if dealer_card_value == 1:\n",
    "            self.dealer_top_card_value_str = \"A\"\n",
    "        elif dealer_card_value == 10:\n",
    "            self.dealer_top_card_value_str = self.np_random.choice([\"J\", \"Q\", \"K\"])\n",
    "        else:\n",
    "            self.dealer_top_card_value_str = str(dealer_card_value)\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode is None:\n",
    "            gym.logger.warn(\n",
    "                \"You are calling render method without specifying any render mode. \"\n",
    "                \"You can specify the render_mode at initialization, \"\n",
    "                f'e.g. gym(\"{self.spec.id}\", render_mode=\"rgb_array\")'\n",
    "            )\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            import pygame\n",
    "        except ImportError:\n",
    "            raise DependencyNotInstalled(\n",
    "                \"pygame is not installed, run `pip install gym[toy_text]`\"\n",
    "            )\n",
    "\n",
    "        player_sum, dealer_card_value, usable_ace = self._get_obs()\n",
    "        screen_width, screen_height = 600, 500\n",
    "        card_img_height = screen_height // 3\n",
    "        card_img_width = int(card_img_height * 142 / 197)\n",
    "        spacing = screen_height // 20\n",
    "\n",
    "        bg_color = (7, 99, 36)\n",
    "        white = (255, 255, 255)\n",
    "\n",
    "        if not hasattr(self, \"screen\"):\n",
    "            pygame.init()\n",
    "            if self.render_mode == \"human\":\n",
    "                pygame.display.init()\n",
    "                self.screen = pygame.display.set_mode((screen_width, screen_height))\n",
    "            else:\n",
    "                pygame.font.init()\n",
    "                self.screen = pygame.Surface((screen_width, screen_height))\n",
    "\n",
    "        if not hasattr(self, \"clock\"):\n",
    "            self.clock = pygame.time.Clock()\n",
    "\n",
    "        self.screen.fill(bg_color)\n",
    "\n",
    "        def get_image(path):\n",
    "            cwd = os.path.dirname(__file__)\n",
    "            image = pygame.image.load(os.path.join(cwd, path))\n",
    "            return image\n",
    "\n",
    "        def get_font(path, size):\n",
    "            cwd = os.path.dirname(__file__)\n",
    "            font = pygame.font.Font(os.path.join(cwd, path), size)\n",
    "            return font\n",
    "\n",
    "        small_font = get_font(\n",
    "            os.path.join(\"font\", \"Minecraft.ttf\"), screen_height // 15\n",
    "        )\n",
    "        dealer_text = small_font.render(\n",
    "            \"Dealer: \" + str(dealer_card_value), True, white\n",
    "        )\n",
    "        dealer_text_rect = self.screen.blit(dealer_text, (spacing, spacing))\n",
    "\n",
    "        def scale_card_img(card_img):\n",
    "            return pygame.transform.scale(card_img, (card_img_width, card_img_height))\n",
    "\n",
    "        dealer_card_img = scale_card_img(\n",
    "            get_image(\n",
    "                os.path.join(\n",
    "                    \"img\",\n",
    "                    f\"{self.dealer_top_card_suit}{self.dealer_top_card_value_str}.png\",\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        dealer_card_rect = self.screen.blit(\n",
    "            dealer_card_img,\n",
    "            (\n",
    "                screen_width // 2 - card_img_width - spacing // 2,\n",
    "                dealer_text_rect.bottom + spacing,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        hidden_card_img = scale_card_img(get_image(os.path.join(\"img\", \"Card.png\")))\n",
    "        self.screen.blit(\n",
    "            hidden_card_img,\n",
    "            (\n",
    "                screen_width // 2 + spacing // 2,\n",
    "                dealer_text_rect.bottom + spacing,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        player_text = small_font.render(\"Player\", True, white)\n",
    "        player_text_rect = self.screen.blit(\n",
    "            player_text, (spacing, dealer_card_rect.bottom + 1.5 * spacing)\n",
    "        )\n",
    "\n",
    "        large_font = get_font(os.path.join(\"font\", \"Minecraft.ttf\"), screen_height // 6)\n",
    "        player_sum_text = large_font.render(str(player_sum), True, white)\n",
    "        player_sum_text_rect = self.screen.blit(\n",
    "            player_sum_text,\n",
    "            (\n",
    "                screen_width // 2 - player_sum_text.get_width() // 2,\n",
    "                player_text_rect.bottom + spacing,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        if usable_ace:\n",
    "            usable_ace_text = small_font.render(\"usable ace\", True, white)\n",
    "            self.screen.blit(\n",
    "                usable_ace_text,\n",
    "                (\n",
    "                    screen_width // 2 - usable_ace_text.get_width() // 2,\n",
    "                    player_sum_text_rect.bottom + spacing // 2,\n",
    "                ),\n",
    "            )\n",
    "        if self.render_mode == \"human\":\n",
    "            pygame.event.pump()\n",
    "            pygame.display.update()\n",
    "            self.clock.tick(self.metadata[\"render_fps\"])\n",
    "        else:\n",
    "            return np.transpose(\n",
    "                np.array(pygame.surfarray.pixels3d(self.screen)), axes=(1, 0, 2)\n",
    "            )\n",
    "\n",
    "    def close(self):\n",
    "        if hasattr(self, \"screen\"):\n",
    "            import pygame\n",
    "\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n",
    "\n",
    "\n",
    "# env = gym.make(\"Blackjack-v1\", sab=True)\n",
    "env = BlackjackEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a9a49c0-23e6-44d6-899a-1f262f157954",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlackjackAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate: float,\n",
    "        initial_epsilon: float,\n",
    "        epsilon_decay: float,\n",
    "        final_epsilon: float,\n",
    "        discount_factor: float = 0.95,\n",
    "    ):\n",
    "        \"\"\"Initialize a Reinforcement Learning agent with an empty dictionary\n",
    "        of state-action values (q_values), a learning rate and an epsilon.\n",
    "\n",
    "        Args:\n",
    "            learning_rate: The learning rate\n",
    "            initial_epsilon: The initial epsilon value\n",
    "            epsilon_decay: The decay for epsilon\n",
    "            final_epsilon: The final epsilon value\n",
    "            discount_factor: The discount factor for computing the Q-value\n",
    "        \"\"\"\n",
    "        self.q_values = defaultdict(lambda: np.zeros(env.action_space.n))\n",
    "\n",
    "        self.lr = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "\n",
    "        self.epsilon = initial_epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.final_epsilon = final_epsilon\n",
    "\n",
    "        self.training_error = []\n",
    "\n",
    "    def get_action(self, obs: tuple[int, int, bool]) -> int:\n",
    "        \"\"\"\n",
    "        Returns the best action with probability (1 - epsilon)\n",
    "        otherwise a random action with probability epsilon to ensure exploration.\n",
    "        \"\"\"\n",
    "        # with probability epsilon return a random action to explore the environment\n",
    "        if np.random.random() < self.epsilon:\n",
    "            return env.action_space.sample()\n",
    "\n",
    "        # with probability (1 - epsilon) act greedily (exploit)\n",
    "        else:\n",
    "            return int(np.argmax(self.q_values[obs]))\n",
    "\n",
    "    def update(\n",
    "        self,\n",
    "        obs: tuple[int, int, bool],\n",
    "        action: int,\n",
    "        reward: float,\n",
    "        terminated: bool,\n",
    "        next_obs: tuple[int, int, bool],\n",
    "    ):\n",
    "        \"\"\"Updates the Q-value of an action.\"\"\"\n",
    "        future_q_value = (not terminated) * np.max(self.q_values[next_obs])\n",
    "        temporal_difference = (\n",
    "            reward + self.discount_factor * future_q_value - self.q_values[obs][action]\n",
    "        )\n",
    "\n",
    "        self.q_values[obs][action] = (\n",
    "            self.q_values[obs][action] + self.lr * temporal_difference\n",
    "        )\n",
    "        self.training_error.append(temporal_difference)\n",
    "\n",
    "    def decay_epsilon(self):\n",
    "        self.epsilon = max(self.final_epsilon, self.epsilon - epsilon_decay)\n",
    "\n",
    "    def save_state(self, path):\n",
    "        state = {\n",
    "            \"lr\": self.lr,\n",
    "            \"discount_factor\": self.discount_factor,\n",
    "            \"epsilon\": self.epsilon,\n",
    "            \"epsilon_decay\": self.epsilon_decay,\n",
    "            \"final_epsilon\": self.final_epsilon,\n",
    "            \"training_error\": self.training_error,\n",
    "            \"q_values\": dict(self.q_values)\n",
    "        }\n",
    "        with open(path, 'wb') as file:\n",
    "            pickle.dump(state, file)\n",
    "        \n",
    "    def load_state(self, path):\n",
    "        with open(path, 'rb') as file:\n",
    "            state = pickle.load(file)\n",
    "            self.lr = state[\"lr\"]\n",
    "            self.epsilon = state[\"epsilon\"]\n",
    "            self.epsilon_decay = state[\"epsilon_decay\"]\n",
    "            self.final_epsilon = state[\"final_epsilon\"]\n",
    "            self.training_error = state[\"training_error\"]\n",
    "            self.lr = state[\"lr\"]\n",
    "            self.q_values = defaultdict(lambda: np.zeros(env.action_space.n), state[\"q_values\"])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72d2afb2-7858-4ea5-8a61-640472e0802b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "learning_rate = 0.01\n",
    "n_episodes = 100_000\n",
    "start_epsilon = 1.0\n",
    "epsilon_decay = start_epsilon / (n_episodes / 2)  # reduce the exploration over time\n",
    "final_epsilon = 0.1\n",
    "\n",
    "agent = BlackjackAgent(\n",
    "    learning_rate=learning_rate,\n",
    "    initial_epsilon=start_epsilon,\n",
    "    epsilon_decay=epsilon_decay,\n",
    "    final_epsilon=final_epsilon,\n",
    ")\n",
    "\n",
    "agent.load_state(\"state.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "601a9d11-6eb5-41b7-a6cc-66624f8897ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 42, 0: 16, -1: 42}\n"
     ]
    }
   ],
   "source": [
    "res = {\n",
    "    1: 0,\n",
    "    0: 0,\n",
    "    -1: 0\n",
    "    }\n",
    "\n",
    "for episode in range(100):\n",
    "    # print(\"-\" * 80)\n",
    "    obs, info = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = agent.get_action(obs)\n",
    "        next_obs, reward, terminated, truncated, info = env.step(action)\n",
    "        agent.update(obs, action, reward, terminated, next_obs)\n",
    "        done = terminated or truncated\n",
    "        if done:\n",
    "            # print(reward)\n",
    "            res[reward] += 1\n",
    "        obs = next_obs\n",
    "\n",
    "    agent.decay_epsilon()\n",
    "    # print(\"-\" * 80)\n",
    "\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
